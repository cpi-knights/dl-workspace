{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"datasets/flower_photos/roses/159079265_d77a9ac920_n.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the image\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"Image not found.\")\n",
    "original_image = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(image=cv2.typing.MatLike, title= str):\n",
    "    # Save or display the result\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(original_image, \"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Automatically detect object region (using simple thresholding here for demonstration)\n",
    "gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "_, binary = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(binary, \"Binary Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours to get a bounding box\n",
    "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "largest_contour = max(contours, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "# Step 3: Initialize mask for GrabCut\n",
    "mask = np.zeros(original_image.shape[:2], dtype=np.uint8)\n",
    "rect = (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(mask, \"Binary Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Allocate background and foreground models\n",
    "bg_model = np.zeros((1, 65), dtype=np.float64)\n",
    "fg_model = np.zeros((1, 65), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(bg_model, \"Binary Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] applying GrabCut took 1.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# apply GrabCut using the the bounding box segmentation method\n",
    "start = time.time()\n",
    "(mask, bg_model, fg_model) = cv2.grabCut(image, mask, rect, bg_model,\n",
    "                                       fg_model, iterCount=10, mode=cv2.GC_INIT_WITH_RECT)\n",
    "end = time.time()\n",
    "print(\"[INFO] applying GrabCut took {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing mask for 'Definite Background'\n",
      "[INFO] showing mask for 'Probable Background'\n",
      "[INFO] showing mask for 'Definite Foreground'\n",
      "[INFO] showing mask for 'Probable Foreground'\n"
     ]
    }
   ],
   "source": [
    "# the output mask has for possible output values, marking each pixel\n",
    "# in the mask as (1) definite background, (2) definite foreground,\n",
    "# (3) probable background, and (4) probable foreground\n",
    "values = (\n",
    "\t(\"Definite Background\", cv2.GC_BGD),\n",
    "\t(\"Probable Background\", cv2.GC_PR_BGD),\n",
    "\t(\"Definite Foreground\", cv2.GC_FGD),\n",
    "\t(\"Probable Foreground\", cv2.GC_PR_FGD),\n",
    ")\n",
    "# loop over the possible GrabCut mask values\n",
    "for (name, value) in values:\n",
    "\t# construct a mask that for the current value\n",
    "\tprint(\"[INFO] showing mask for '{}'\".format(name))\n",
    "\tvalueMask = (mask == value).astype(\"uint8\") * 255\n",
    "\t# display the mask so we can visualize it\n",
    "\tcv2.imshow(name, valueMask)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll set all definite background and probable background pixels\n",
    "# to 0 while definite foreground and probable foreground pixels are\n",
    "# set to 1\n",
    "outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),\n",
    "                      0, 1)\n",
    "# scale the mask from the range [0, 1] to [0, 255]\n",
    "outputMask = (outputMask * 255).astype(\"uint8\")\n",
    "# apply a bitwise AND to the image using our mask generated by\n",
    "# GrabCut to generate our final output image\n",
    "output = cv2.bitwise_and(image, image, mask=outputMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the input image followed by the mask and output generated by\n",
    "# GrabCut and bitwise masking\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"GrabCut Mask\", outputMask)\n",
    "cv2.imshow(\"GrabCut Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(c, \"Binary Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the mask to binary format\n",
    "mask_2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "segmented_image = original_image * mask_2[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.any(mask == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "segmented_result = automatic_grabcut(image_path)\n",
    "\n",
    "# Save or display the result\n",
    "cv2.imwrite(\"segmented_output.jpg\", segmented_result)\n",
    "cv2.imshow(\"Segmented Image\", segmented_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def automatic_grabcut(image_path):\n",
    "    \"\"\"\n",
    "    Perform automatic GrabCut segmentation on an image.\n",
    "\n",
    "    Args:\n",
    "    - image_path: Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_image: The image with the background removed.\n",
    "    \"\"\"\n",
    "    # Step 1: Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image at {image_path} not found.\")\n",
    "    original_image = image.copy()\n",
    "\n",
    "    # Step 2: Convert to grayscale for better processing\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 3: Apply thresholding to roughly isolate the object\n",
    "    _, binary = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 4: Find contours to get a bounding box\n",
    "    contours, _ = cv2.findContours(\n",
    "        binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        raise ValueError(\n",
    "            \"No contours found. Ensure the image has distinguishable foreground and background.\")\n",
    "\n",
    "    # Get the largest contour (assuming the object occupies the largest area)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Step 5: Initialize the mask for GrabCut\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    rect = (x, y, w, h)\n",
    "\n",
    "    # Mark probable foreground in the bounding box area\n",
    "    mask[y:y + h, x:x + w] = cv2.GC_PR_FGD\n",
    "\n",
    "    # Step 6: Allocate background and foreground models\n",
    "    bg_model = np.zeros((1, 65), dtype=np.float64)\n",
    "    fg_model = np.zeros((1, 65), dtype=np.float64)\n",
    "\n",
    "    # Step 7: Apply GrabCut with the mask initialization\n",
    "    cv2.grabCut(image, mask, rect, bg_model, fg_model,\n",
    "                iterCount=5, mode=cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "    # Step 8: Create the final binary mask\n",
    "    mask_2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    # Step 9: Apply the mask to the original image\n",
    "    segmented_image = original_image * mask_2[:, :, np.newaxis]\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "\n",
    "segmented_image = automatic_grabcut(image_path)\n",
    "\n",
    "# Save and display the result\n",
    "cv2.imwrite(\"segmented_output.jpg\", segmented_image)\n",
    "cv2.imshow(\"Segmented Image\", segmented_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show(image, \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
